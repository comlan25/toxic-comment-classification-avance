# ‚ö†Ô∏è D√©tection Avanc√©e de Commentaires Toxiques (NLP)

Ce projet constitue la **suite √©volutive** du projet `toxic-comment-classification`. Alors que la premi√®re version se concentrait sur des mod√®les de Machine Learning classiques (TF-IDF, SVM, Random Forest), cette it√©ration adopte une **approche beaucoup plus avanc√©e** int√©grant le Deep Learning et les Large Language Models (LLM).

## √âvolution du Projet
Par rapport √† la version initiale, ce d√©p√¥t introduit :
* **Vecteurs de mots contextuels** (Word Embeddings pr√©-entra√Æn√©s).
* **Mod√®les de langage transformeurs** (BERT) pour une compr√©hension s√©mantique profonde.
* **Techniques de Prompt Engineering** pour √©valuer les capacit√©s de raisonnement des mod√®les modernes.

## Fonctionnalit√©s Avanc√©es
Le notebook explore trois piliers technologiques :

1. **Vecteurs Pr√©-entra√Æn√©s (GloVe)** : Utilisation de **GloVe (300d)** avec une R√©gression Logistique pour capturer les relations s√©mantiques entre les mots.
2. **Deep Learning (Transformers)** : Mise en ≈ìuvre de **Toxic-BERT** via Hugging Face, atteignant un niveau de pr√©cision in√©gal√© pour la d√©tection de nuances fines de toxicit√©.
3. **Prompt Engineering (LLM)** : Comparaison de strat√©gies **Zero-shot**, **Role prompting** et **Few-shot prompting** avec le mod√®le **BART-large-mnli** pour tester la classification sans r√©entra√Ænement.

## Performance & Comparaison
Les r√©sultats d√©montrent la sup√©riorit√© des approches bas√©es sur les Transformers par rapport au projet initial :

* **Transformers (BERT)** : Performances exceptionnelles avec une **Accuracy de 98%** et un **AUC de 0.995**.
* **GloVe + LR** : Approche robuste et rapide avec un **AUC de 0.947**.
* **Prompt Engineering** : Le **Few-shot prompting** montre une nette am√©lioration par rapport au Zero-shot, prouvant l'importance du contexte pour les LLM.

## Stack Technique
* Langage : Python
* NLP : NLTK, Gensim, Hugging Face Transformers
* ML : Scikit-learn
* Visualisation : Seaborn, Matplotlib

## üìä Performance & Comparaison
## üìä Performance & Comparaison
Les r√©sultats d√©montrent la sup√©riorit√© des approches bas√©es sur les Transformers par rapport au projet initial :

* **Transformers (BERT)** : Performances exceptionnelles avec une **Accuracy de 98%** et un **AUC de 0.995**.
* **GloVe + LR** : Approche robuste et rapide avec un **AUC de 0.947**.
* **Prompt Engineering** : Le **Few-shot prompting** montre une nette am√©lioration par rapport au Zero-shot, prouvant l'importance du contexte pour les LLM.


## üõ†Ô∏è Installation
```bash
# Cloner le d√©p√¥t de cette version avanc√©e
git clone [https://github.com/comlan25/toxic-comment-classification-avance.git](https://github.com/comlan25/toxic-comment-classification-avance.git)

# Installer les d√©pendances (inclus Transformers, Torch, Gensim)
pip install -r requirements.txt